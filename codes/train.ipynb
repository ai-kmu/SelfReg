{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T06:41:14.997611Z",
     "start_time": "2021-03-24T06:41:14.991292Z"
    }
   },
   "outputs": [],
   "source": [
    "# PACS details\n",
    "domains = ['photo', 'art_painting', 'cartoon', 'sketch']\n",
    "classes = ['dog', 'elephant', 'giraffe', 'guitar', 'horse','house', 'person']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T06:41:16.428691Z",
     "start_time": "2021-03-24T06:41:15.865341Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "\n",
    "import torchvision.datasets as Datasets\n",
    "from torchvision import models\n",
    "from torchvision.datasets import ImageFolder, DatasetFolder\n",
    "\n",
    "from utils import *\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model.resnet18_selfreg import resnet18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T06:41:27.727888Z",
     "start_time": "2021-03-24T06:41:27.716357Z"
    }
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "# Training Setting\n",
    "##############################\n",
    "\n",
    "# Select model to train\n",
    "# resnet18(pytorch official):'resnet18_classic'\n",
    "# SelfReg : 'resnet18' \n",
    "used_model = 'resnet18'\n",
    "\n",
    "save_name = 'SelfReg_official_test'     # save_dir name\n",
    "                                                     # save_path : resnet_18/pacs/{save_name}/\n",
    "dataset ='pacs'        \n",
    "pacs_ver = 'pacs_official_split' \n",
    "number_of_tests = 20   \n",
    "gpu_num = 0\n",
    "n_workers = 6\n",
    "\n",
    "##############################\n",
    "# Basic Hyper-parameters\n",
    "##############################\n",
    "\n",
    "# Training Setting\n",
    "    # classic : classic training\n",
    "    # IDCL : classic + Inter-domain curriculum learning\n",
    "    \n",
    "training_setting = 'IDCL'\n",
    "is_self_reg = True  # Using SefReg Flag\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 128\n",
    "is_pretrained = True  # Use ImageNet pretrain weight ?\n",
    "used_optimizer = 'SGD' # 'Adam' or 'SGD'\n",
    "\n",
    "#Learning rate\n",
    "lr = 4e-3 \n",
    "lr_decay_epoch = [100]\n",
    "lr_decay_gamma = 0.1\n",
    "\n",
    "\n",
    "train_tf, test_tf = get_tf(augment=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T06:41:28.903209Z",
     "start_time": "2021-03-24T06:41:28.869921Z"
    }
   },
   "outputs": [],
   "source": [
    "device= torch.device('cpu')\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"Using CUDA\")\n",
    "    device = torch.device(\"cuda:{}\".format(gpu_num))\n",
    "print(device)\n",
    "\n",
    "\n",
    "\n",
    "#모델 세팅 저장 \n",
    "model_settings={\n",
    "    \"used_model\" : used_model,\n",
    "    \"dataset\" : dataset,\n",
    "    \"save_name\" : save_name,\n",
    "    \"pacs_ver\" : pacs_ver,\n",
    "    \"number_of_tests\" : number_of_tests,\n",
    "    \"training_setting\" : training_setting,\n",
    "    \"epochs\" : epochs,\n",
    "    \"batch_size\" : batch_size,\n",
    "    \"is_pretrained\" : is_pretrained,\n",
    "    \"lr\" : lr,\n",
    "    \"lr_decay_epoch\" : lr_decay_epoch,\n",
    "    \"lr_decay_gamma\" : lr_decay_gamma,\n",
    "    \"gpu_num\" : gpu_num\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T06:41:33.588755Z",
     "start_time": "2021-03-24T06:41:33.518638Z"
    },
    "code_folding": [
     63
    ]
   },
   "outputs": [],
   "source": [
    "def classic_setting(test_domain_idx, domains, batch_size, is_pretrained, train_tf, test_tf, used_model,pacs_ver,used_optimizer):\n",
    "    \n",
    "    train_set1 = ImageFolder(root=os.path.join('{}/train'.format(pacs_ver),\n",
    "                                               domains[(test_domain_idx+1)%len(domains)]), transform = train_tf)\n",
    "    train_set2 = ImageFolder(root=os.path.join('{}/train'.format(pacs_ver),\n",
    "                                               domains[(test_domain_idx+2)%len(domains)]), transform = train_tf)\n",
    "    train_set3 = ImageFolder(root=os.path.join('{}/train'.format(pacs_ver),\n",
    "                                               domains[(test_domain_idx+3)%len(domains)]), transform = train_tf)\n",
    "        \n",
    "    val_set1 = ImageFolder(root=os.path.join('{}/val'.format(pacs_ver),\n",
    "                                               domains[(test_domain_idx+1)%len(domains)]), transform = test_tf)\n",
    "    val_set2 = ImageFolder(root=os.path.join('{}/val'.format(pacs_ver),\n",
    "                                               domains[(test_domain_idx+2)%len(domains)]), transform = test_tf)\n",
    "    val_set3 = ImageFolder(root=os.path.join('{}/val'.format(pacs_ver),\n",
    "                                               domains[(test_domain_idx+3)%len(domains)]), transform = test_tf)\n",
    "    \n",
    "    train_set = train_set1+train_set2+train_set3\n",
    "    val_set = val_set1+val_set2+val_set3\n",
    "    test_set = ImageFolder(root=os.path.join('{}/test'.format(pacs_ver),domains[test_domain_idx]), transform = test_tf)\n",
    "    \n",
    "    \n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=n_workers)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=n_workers)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=n_workers)\n",
    "    \n",
    "    \n",
    "    if used_model=='vgg16':\n",
    "        model = models.vgg16(pretrained=is_pretrained).cuda()\n",
    "        model.classifier[6].out_features=len(classes)\n",
    "    elif used_model=='inceptionv3':\n",
    "        model = models.inception_v3(pretrained=is_pretrained).cuda()\n",
    "        model.AuxLogits.fc.out_features = len(classes)\n",
    "        model.fc.out_features=len(classes)\n",
    "    elif used_model=='resnet18':\n",
    "        # load weights pretrained on ImageNet\n",
    "        model = resnet18(pretrained=is_pretrained)        \n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs,len(classes))\n",
    "        model = model.to(device)\n",
    "    elif used_model=='resnet18_classic':\n",
    "        model = models.resnet18(pretrained=is_pretrained)        \n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs,len(classes))\n",
    "        model = model.to(device)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    if used_optimizer==\"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    elif used_optimizer==\"SGD\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    swa_model = AveragedModel(model).to(device)\n",
    "    swa_scr = SWALR(optimizer, swa_lr=0.004, anneal_epochs=1)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=lr_decay_epoch, gamma= lr_decay_gamma)  \n",
    "\n",
    "    return train_loader, val_loader, test_loader, optimizer, model, scheduler, swa_model, swa_scr\n",
    "\n",
    "\n",
    "    \n",
    "def IDCL_setting(test_domain_idx, domains, batch_size, is_pretrained, train_tf, test_tf, used_model,pacs_ver, used_optimizer):\n",
    "    \n",
    "    check = 1\n",
    "    train_set = 0\n",
    "    val_set = 0\n",
    "    check_limit = 3\n",
    "    \n",
    "    for i in range(4):\n",
    "        if check > check_limit:\n",
    "            break\n",
    "        if i==test_domain_idx:\n",
    "            continue\n",
    "        \n",
    "        temp = ImageFolder(root=os.path.join('{}/train'.format(pacs_ver),domains[i]),\n",
    "                           transform = train_tf)\n",
    "        \n",
    "        temp_val = ImageFolder(root=os.path.join('{}/val'.format(pacs_ver),domains[i]),\n",
    "                               transform = test_tf)\n",
    "        if check==1:\n",
    "            train_set = temp\n",
    "            val_set = temp_val\n",
    "        else:\n",
    "            train_set += temp\n",
    "            val_set += temp_val\n",
    "        \n",
    "        if check==1:\n",
    "            train_set_stage1 = train_set\n",
    "            val_set_stage1 = val_set\n",
    "        elif check==2:\n",
    "            train_set_stage2 = train_set\n",
    "            val_set_stage2 = val_set\n",
    "        elif check==3:\n",
    "            train_set_stage3 = train_set\n",
    "            val_set_stage3 = val_set\n",
    "        \n",
    "        check += 1\n",
    "    \n",
    "    \n",
    "    test_set = ImageFolder(root=os.path.join('{}/test'.format(pacs_ver),domains[test_domain_idx]), transform = test_tf)\n",
    "    \n",
    "    print('stage1 (train,val):',len(train_set_stage1),len(val_set_stage1))\n",
    "    print('stage2 (train,val):',len(train_set_stage2),len(val_set_stage2))\n",
    "    print('stage3 (train,val):',len(train_set_stage3),len(val_set_stage3))\n",
    "    print('test :',len(test_set))\n",
    "    \n",
    "    t_loader1 = DataLoader(train_set_stage1, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "    v_loader1 = DataLoader(val_set_stage1, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "    \n",
    "    t_loader2 = DataLoader(train_set_stage2, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "    v_loader2 = DataLoader(val_set_stage2, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "    \n",
    "    t_loader3 = DataLoader(train_set_stage3, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "    v_loader3 = DataLoader(val_set_stage3, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "    \n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=6)\n",
    "\n",
    "    \n",
    "    if used_model=='vgg16':\n",
    "        print('vgg16')\n",
    "        model = models.vgg16(pretrained=is_pretrained).cuda()\n",
    "        model.classifier[6].out_features=7\n",
    "    elif used_model=='inceptionv3':\n",
    "        model = models.inception_v3(pretrained=is_pretrained).cuda()\n",
    "        model.AuxLogits.fc.out_features = 7\n",
    "        model.fc.out_features=7\n",
    "    elif used_model=='resnet18':\n",
    "        model = resnet18(pretrained=is_pretrained)        \n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs,7)\n",
    "        model = model.to(device)\n",
    "    elif used_model=='resnet18_classic':\n",
    "        model = models.resnet18(pretrained=is_pretrained)        \n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs,7)\n",
    "        model = model.to(device)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    if used_optimizer==\"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    elif used_optimizer==\"SGD\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=lr_decay_epoch, gamma= lr_decay_gamma)  \n",
    "    swa_model = AveragedModel(model).to(device)\n",
    "    swa_scr = SWALR(optimizer, swa_lr=0.004, anneal_epochs=1)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=lr_decay_epoch, gamma= lr_decay_gamma)  \n",
    "    \n",
    "    train_loaders = [t_loader1,t_loader2, t_loader3]\n",
    "    val_loaders = [v_loader1, v_loader2, v_loader3]\n",
    "    return train_loaders, val_loaders, test_loader, optimizer, model, lr_scheduler, swa_model, swa_scr \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:12:31.513758Z",
     "start_time": "2021-03-24T06:42:35.440178Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_model_setting(model_settings,used_model,domains,dataset,save_name)\n",
    "\n",
    "for i in range(1,number_of_tests+1):\n",
    "    try_check = i\n",
    "    \n",
    "    for test_idx in [3,2,1,0]:\n",
    "        \n",
    "        ##########################\n",
    "        #### Training Setting ####\n",
    "        ##########################\n",
    "        if training_setting=='classic':\n",
    "            train_loader, val_loader, test_loader, optimizer, model, lr_scheduler, swa_model, swa_scr = classic_setting(\n",
    "                test_idx, domains, batch_size, is_pretrained, train_tf, test_tf, used_model, pacs_ver,used_optimizer\n",
    "            )\n",
    "        elif training_setting=='IDCL':\n",
    "            train_loaders, val_loaders, test_loader, optimizer, model, lr_scheduler,swa_model, swa_scr = IDCL_setting(\n",
    "                test_idx, domains, batch_size, is_pretrained, train_tf, test_tf, used_model, pacs_ver, used_optimizer\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        save_dir = save_route(test_idx, domains, dataset, save_name, used_model)\n",
    "        \n",
    "\n",
    "        try:\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "        except:\n",
    "            print('Error : Creating directory. '+ save_dir)\n",
    "        \n",
    "                \n",
    "        ##########################\n",
    "        ####     Training     ####\n",
    "        ##########################\n",
    "        \n",
    "        if training_setting=='classic':\n",
    "            model, losses, accuracies = classic_training(\n",
    "                device, epochs, model,optimizer, criterion, train_loader, val_loader, \n",
    "                lr_scheduler,is_self_reg=is_self_reg, \n",
    "                swa_model=swa_model, swa_scr=swa_scr\n",
    "            )\n",
    "            test_accuracy,_,__ = classic_test(device, model,criterion, test_loader,used_model, save_dir, try_check)\n",
    "        elif training_setting=='IDCL':\n",
    "            model, losses, accuracies = IDCL_training(\n",
    "                device, epochs, model,optimizer, criterion, \n",
    "                train_loaders, val_loaders,\n",
    "                lr_scheduler, is_self_reg=is_self_reg,\n",
    "                swa_model=swa_model, swa_scr=swa_scr\n",
    "            )\n",
    "            test_accuracy,_,__ = classic_test(device, model,criterion, test_loader,used_model, save_dir, try_check)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "            \n",
    "\n",
    "        total_result_text_path=os.path.join(save_dir,\"test_total_result.txt\")\n",
    "        with open(total_result_text_path,\"a\") as f:\n",
    "            print(test_accuracy)\n",
    "            f.write(str(test_accuracy)+\"\\n\")    \n",
    "            \n",
    "            \n",
    "        plotting(losses, accuracies, used_model, save_dir, is_pretrained, try_check)\n",
    "#         save_model(model, used_model, save_dir, is_pretrained, try_check)\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "499.4px",
    "left": "954px",
    "right": "20px",
    "top": "239px",
    "width": "503px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
